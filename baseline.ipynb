{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# change directory if necessary\n",
    "os.chdir(r\"/Users/hokongzheng/Downloads/FIT3162---Zhiwei-and-Friends/\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset into variables (including preprocessing)\n",
    "For our own dataset, preprocessing is done in another python file.\n",
    "\n",
    "For SemEval dataset, just read it directly. \n",
    "\n",
    "(Note: Review Column Name for SemEval dataset is \"text\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For our own dataset\n",
    "from preprocessing import *\n",
    "data = readfile()\n",
    "review_list = data[\"Reviews\"].apply(string_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews: 3044\n",
      "Explicit Aspects: service, food, anecdotes/miscellaneous, ambience, price\n"
     ]
    }
   ],
   "source": [
    "# For SemEval datasets\n",
    "def readfile(filename):\n",
    "    data = pd.read_excel(filename)\n",
    "    data = data.dropna(subset=[\"text\"])\n",
    "    return data\n",
    "\n",
    "filename = \"Restaurants_Train.xlsx\"\n",
    "data = readfile(filename)\n",
    "review_list = data[\"text\"]\n",
    "explicit_aspect = pd.unique(data[\"category\"])\n",
    "print(\"Number of Reviews:\", len(review_list))\n",
    "print(\"Explicit Aspects:\", \", \".join(explicit_aspect))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to extract nouns from a sentence\n",
    "\n",
    "Generalization techniques are used in this function, which are:\n",
    "\n",
    "- Lowercase\n",
    "> American $\\rightarrow$ american\n",
    "\n",
    "- Stemming\n",
    "> services $\\rightarrow$ servic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() # used for stemming\n",
    "\n",
    "def get_nouns(sentence):\n",
    "    nouns = [] # store all nouns from a given sentence\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "    for word, pos in nltk.pos_tag(tokenized_sentence):\n",
    "        if pos in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            nouns.append(stemmed_word.lower())\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all nouns from the review column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For our own dataset\n",
    "all_nouns = []\n",
    "for reviews_from_each_restaurant in review_list:\n",
    "    nouns_from_each_restaurant = map(get_nouns, reviews_from_each_restaurant)\n",
    "    flattened_nouns = list(itertools.chain(*nouns_from_each_restaurant))\n",
    "    all_nouns.extend(flattened_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nouns = []\n",
    "for reviews_from_each_restaurant in review_list:\n",
    "    nouns_from_each_restaurant = get_nouns(reviews_from_each_restaurant)\n",
    "    all_nouns.extend(nouns_from_each_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a frequency table and get top k most frequent nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nouns: 9986\n",
      "Top 10 Frequent Nouns: [('food', 464), ('place', 328), ('servic', 246), ('restaur', 241), ('time', 150), ('price', 115), ('menu', 82), ('pizza', 82), ('dish', 77), ('dinner', 76)]\n"
     ]
    }
   ],
   "source": [
    "frequency_table = FreqDist(all_nouns)\n",
    "k = 10\n",
    "print(\"Number of Nouns:\", frequency_table.N())\n",
    "print(\"Top {} Frequent Nouns: {}\".format(k, frequency_table.most_common(k)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "True Labels:service, food, anecdotes/miscellaneous, ambience, price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
