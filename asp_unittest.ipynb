{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Testing - Unittest\n",
    "The functions used for both aspect term extraction and aggregation are copied here because of some modification on them. The reason why we want to modify them is because some parts of the functions are not able to be tested (e.g. model prediction). Hence, copying functions to this file reduces the risk of having buggy code and also allows us to have more flexibilities.\n",
    "## Load python unittest module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Extraction\n",
    "### Functions that need to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_type(tok, idx_to_tag):\n",
    "    tag_name = idx_to_tag[tok]\n",
    "    tag_class = tag_name.split('-')[0]\n",
    "    tag_type = tag_name.split('-')[-1]\n",
    "    return tag_class, tag_type\n",
    "\n",
    "def _pad_sequences(sequences, pad_tok, max_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    sequence_padded, sequence_length = [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        seq = list(seq)\n",
    "        seq_ = seq[:max_length] + [pad_tok]*max(max_length - len(seq), 0)\n",
    "        sequence_padded +=  [seq_]\n",
    "        sequence_length += [min(len(seq), max_length)]\n",
    "\n",
    "    return sequence_padded, sequence_length\n",
    "\n",
    "def get_char_vocab(dataset):\n",
    "    vocab_char = set()\n",
    "    for words, _ in dataset:\n",
    "        for word in words:\n",
    "            vocab_char.update(word)\n",
    "\n",
    "    return vocab_char\n",
    "\n",
    "def get_vocabs(datasets):\n",
    "    vocab_words = set()\n",
    "    vocab_tags = set()\n",
    "    for dataset in datasets:\n",
    "        for words, tags in dataset:\n",
    "            vocab_words.update(words)\n",
    "            vocab_tags.update(tags)\n",
    "    return vocab_words, vocab_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a49cc75f8>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.token1 = 1\n",
    "        self.tag1 = {1: \"B-PER\"}\n",
    "        self.token2 = 2\n",
    "        self.tag2 = {2: \"ABC-ABC\"}\n",
    "        self.token3 = 3\n",
    "        self.tag3 = {3: \"O-GPE\"}\n",
    "        self.token4 = \"4\"\n",
    "        self.tag4 = {4: \"B-PER\"}\n",
    "        self.token5 = 5\n",
    "        self.tag5 = {5: \"I-LOC\"}\n",
    "    \n",
    "    def test_get_chunk_type(self):\n",
    "        \"\"\"\n",
    "        Test function get_chunk_type\n",
    "        \"\"\"\n",
    "        self.assertEqual(get_chunk_type(self.token1, self.tag1), (\"B\", \"PER\"))\n",
    "        self.assertEqual(get_chunk_type(self.token2, self.tag2), (\"ABC\", \"ABC\"))\n",
    "        self.assertEqual(get_chunk_type(self.token3, self.tag3), (\"O\", \"GPE\"))\n",
    "        try:\n",
    "            get_chunk_type(self.token4, self.tag4)\n",
    "        except Exception as e:\n",
    "            self.assertEqual(type(e), KeyError)\n",
    "        self.assertEqual(get_chunk_type(self.token5, self.tag5), (\"I\", \"LOC\"))\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a49cac978>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.seq1 = [[1,2,3], [2,3]]\n",
    "        self.pad_tok1 = \"_PAD\"\n",
    "        self.maxlen1 = 5\n",
    "        \n",
    "        self.seq2 = [[1], [\"a\",\"b\",\"c\",\"d\"]]\n",
    "        self.pad_tok2 = \"_PAD\"\n",
    "        self.maxlen2 = 4\n",
    "\n",
    "    def test__pad_sequences(self):\n",
    "        \"\"\"\n",
    "        Test function _pad_sequences\n",
    "        \"\"\"\n",
    "        self.assertEqual(_pad_sequences(self.seq1, self.pad_tok1, self.maxlen1), \\\n",
    "                         ([[1,2,3,\"_PAD\",\"_PAD\"],[2,3,\"_PAD\",\"_PAD\",\"_PAD\"]], [3,2]))\n",
    "        self.assertEqual(_pad_sequences(self.seq2, self.pad_tok2, self.maxlen2), \\\n",
    "                         ([[1,\"_PAD\",\"_PAD\",\"_PAD\"],[\"a\",\"b\",\"c\",\"d\"]], [1,4]))\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a49d79eb8>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.dataset1 = [\n",
    "            [[\"beautiful\"],[\"JJ\"]],\n",
    "            [[\"beauty\"],[\"NN\"]],\n",
    "            [[\"he\"],[\"PP\"]]\n",
    "        ]\n",
    "        self.dataset2 = [\n",
    "            [[\"works\"],[\"VB\"]],\n",
    "            [[\"hard\"],[\"RB\"]],\n",
    "            [[\"the\"],[\"DT\"]]\n",
    "        ]\n",
    "\n",
    "    def test_get_char_vocab(self):\n",
    "        \"\"\"\n",
    "        Test function get_char_vocab\n",
    "        \"\"\"\n",
    "        result1 = set()\n",
    "        result1.update(\"beautiful\")\n",
    "        result1.update(\"beauty\")\n",
    "        result1.update(\"he\")\n",
    "        result2 = set()\n",
    "        result2.update(\"works\")\n",
    "        result2.update(\"hard\")\n",
    "        result2.update(\"the\")\n",
    "        \n",
    "        self.assertEqual(get_char_vocab(self.dataset1), result1)\n",
    "        self.assertEqual(get_char_vocab(self.dataset2), result2)\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a49cacf60>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.dataset1 = [[\n",
    "            [[\"beautiful\"],[\"JJ\"]],\n",
    "            [[\"beauty\"],[\"NN\"]],\n",
    "            [[\"he\"],[\"PP\"]]\n",
    "        ]]\n",
    "        self.dataset2 = [[\n",
    "            [[\"works\"],[\"VB\"]],\n",
    "            [[\"hard\"],[\"RB\"]],\n",
    "            [[\"the\"],[\"DT\"]]\n",
    "        ]]\n",
    "\n",
    "    def test_get_vocabs(self):\n",
    "        \"\"\"\n",
    "        Test function get_vocabs\n",
    "        \"\"\"\n",
    "        result1 = (\n",
    "            {\"beautiful\",\"beauty\",\"he\"},\n",
    "            {\"JJ\",\"NN\",\"PP\"}\n",
    "        )\n",
    "        result2 = (\n",
    "            set([\"works\",\"hard\",\"the\"]),\n",
    "            set([\"VB\",\"RB\",\"DT\"])\n",
    "        )\n",
    "        self.assertEqual(get_vocabs(self.dataset1), result1)\n",
    "        self.assertEqual(get_vocabs(self.dataset2), result2)\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Aggregation\n",
    "### Functions that need to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# Flatten list of list\n",
    "def _flatten(l):\n",
    "    \"\"\"\n",
    "    This function will flatten a list of list to a list. (e.g. [[1],[2]] -> [1, 2])\n",
    "    :arg {l} - a list of list\n",
    "    :return - flattened list\n",
    "    \"\"\"\n",
    "    return list(itertools.chain.from_iterable(l))\n",
    "\n",
    "def _clean_text(text, stopwords=set(stopwords.words(\"english\"))): #, lemmatizer=WordNetLemmatizer()):\n",
    "    \"\"\"\n",
    "    This function is used for the preprocessing step, which will\n",
    "    - convert text to lowercase\n",
    "    - remove quotations surrounding the word (e.g. 'perks' -> perks)\n",
    "    - handle some contraction of words (e.g. he's -> he is, can't -> cannot)\n",
    "    - remove multiple consecutive spaces\n",
    "    - remove the space that starts or ends in the sentence\n",
    "    - remove stopwords\n",
    "    (Note: the lemmatization has been done for this and we found that it did not provide a better result)\n",
    "    :arg {text} - a string (sentence)\n",
    "    :arg {stopwords} - a set of words \n",
    "    :return - preprocessed string\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\'(\\w*)\\'\", r\"\\1\", text)\n",
    "    text = re.sub(r\"(he|she|it)\\'s\", r\"\\1 is\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    text = \" \".join([w for w in word_tokenize(text) if not w in stopwords])\n",
    "    return text\n",
    "\n",
    "def _readXML(filename):\n",
    "    \"\"\"\n",
    "    This function is to read SemEval Dataset in XML format. Here, we only 7 columns, which are:\n",
    "    ['review', 'term', 'termPolarity', 'startIndex', 'endIndex','aspect', 'aspectPolarity']\n",
    "    :arg {filename} - the dataset file (e.g. \"Restaurant_Train.xml\")\n",
    "    :return - pandas dataframe\n",
    "    \"\"\"\n",
    "    table = []\n",
    "    row = [np.NaN] * 7\n",
    "    \n",
    "    for event, node in et.iterparse(filename, events=(\"start\", \"end\")):\n",
    "\n",
    "        if node.tag == \"text\":\n",
    "            row[0] = node.text\n",
    "        elif node.tag == \"aspectTerms\" and event == \"start\":\n",
    "            row[1] = []\n",
    "            row[2] = []\n",
    "            row[3] = []\n",
    "            row[4] = []\n",
    "        elif node.tag == \"aspectTerm\" and event == \"start\":\n",
    "            row[1].append(node.attrib.get(\"term\").replace(\"-\", \" \").replace(\"/\", \" \"))\n",
    "            row[2].append(node.attrib.get(\"polarity\"))\n",
    "            row[3].append(int(node.attrib.get(\"from\")))\n",
    "            row[4].append(int(node.attrib.get(\"to\")))\n",
    "        elif node.tag == \"aspectCategories\" and event == \"start\":\n",
    "            row[5] = []\n",
    "            row[6] = []\n",
    "        elif node.tag == \"aspectCategory\" and event == \"start\":\n",
    "            row[5].append(node.attrib.get(\"category\"))\n",
    "            row[6].append(node.attrib.get(\"polarity\"))\n",
    "        elif node.tag == \"aspectCategories\" and event == \"end\":\n",
    "            table.append(row)\n",
    "            row = [np.NaN] * 7\n",
    "\n",
    "    dfcols = ['review', 'term', 'termPolarity', 'startIndex', 'endIndex','aspect', 'aspectPolarity']\n",
    "    data = pd.DataFrame(table, columns=dfcols)\n",
    "    data[\"review\"] = data[\"review\"].str.replace(\"-\", \" \")\n",
    "    data[\"review\"] = data[\"review\"].str.replace(\"/\", \" \")\n",
    "    return data\n",
    "    \n",
    "def _add6PosFeautures(sentences, max_sent_len = 65):\n",
    "    \"\"\"\n",
    "    This function is specially made for add 6 POS tag features for the model we have trained.\n",
    "    :arg {sentences} - list of sentences\n",
    "    :arg {max_sent_len} - the maximum sentence length (by default it would be 65)\n",
    "    :return - pos features for given list of sentences\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    pos_tags = [\"CC\",\"NN\",\"JJ\",\"VB\",\"RB\",\"IN\"]\n",
    "    le.fit(pos_tags)\n",
    "    input_data = np.zeros((len(sentences), max_sent_len, len(pos_tags)))\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        tags = nltk.pos_tag(words)\n",
    "        sentence_len = len(tags)\n",
    "        \n",
    "        for j in range(max_sent_len):\n",
    "            if j< sentence_len :\n",
    "                curr_tag = tags[j][1][:2] # only see the first two letters\n",
    "                if curr_tag in pos_tags:                    \n",
    "                    index = (le.transform([curr_tag]))[0]\n",
    "                    input_data[i][j][index] = 1\n",
    "\n",
    "    return np.asarray(input_data)\n",
    "\n",
    "def _oneHotVectorize(df, mlb, le):\n",
    "    \"\"\"\n",
    "    This function acts as a vectorizer that turns a list of aspects into one-hot vector.\n",
    "    However, it is modified to accommodate a multilabel pattern.\n",
    "    :arg {df} - a dataframe (in this case, it would be our dataset)\n",
    "    :arg {mlb} - a multilabel binarizer (from module \"sklearn\")\n",
    "    :arg {le} - a label encoder (from module \"sklearn\")\n",
    "    :return - processed dataframe\n",
    "    \"\"\"\n",
    "    df = df.apply(le.transform)\n",
    "    df = mlb.fit_transform(df)\n",
    "    return df\n",
    "\n",
    "def _modified_performance_measure(preds, label=None):\n",
    "    \"\"\"\n",
    "    This function is a modified version of _performance_measure.\n",
    "    The original _performance_measure function needs a model as its first input.\n",
    "    And the prediction by the model is unpredictable as it would be in a form of a list of 5 probabilities.\n",
    "    Therefore, we modify the function by giving the prediction here and test whether the rest of the code is correct. \n",
    "    :arg {preds} - prediction in probabilities\n",
    "    :arg {label} - the label for the input \n",
    "    :return - accuracy, precision, recall and f1 in a list\n",
    "    \"\"\"\n",
    "    processed_preds = []\n",
    "    for i in range(len(preds)):\n",
    "        pred = list(map(lambda val: 1 if val > 0.175 else 0, preds[i]))\n",
    "        processed_preds.append(pred)\n",
    "        \n",
    "    # return the prediction if no label is provided.\n",
    "    # as this would be in the case where users just want to see the output of model given their inputs \n",
    "    if label is None:\n",
    "        return processed_preds\n",
    "\n",
    "    test_label = processed_preds\n",
    "    true_label = label\n",
    "\n",
    "    total_pos = .0\n",
    "    total_neg = .0\n",
    "    tp = .0 # True Positive\n",
    "    tn = .0 # True Negative\n",
    "    for i in range(len(test_label)):\n",
    "        for j in range(len(test_label[0])):\n",
    "            if test_label[i][j] == 1:\n",
    "                total_pos += 1\n",
    "                if true_label[i][j] ==1:\n",
    "                    tp +=1\n",
    "            if test_label[i][j] == 0:\n",
    "                total_neg += 1\n",
    "                if true_label[i][j] ==0:\n",
    "                    tn += 1\n",
    "    fp = total_neg - tn # False Positive\n",
    "    fn = total_pos - tp # False Negative\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/total_pos\n",
    "    f1 = 2 * (precision * recall)/(precision + recall)\n",
    "    acc = (tp + tn)/(total_pos + total_neg)\n",
    "\n",
    "    return list(map(lambda x:round(x,2),[acc, precision, recall, f1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x10d2f1d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def test_flatten(self):\n",
    "        \"\"\"\n",
    "        Test function _flatten\n",
    "        \"\"\"\n",
    "        self.assertEqual(_flatten([[1], [2]]), [1, 2])\n",
    "        self.assertEqual(_flatten([[\"a\",\"b\"], [\"c\"]]), [\"a\", \"b\", \"c\"])\n",
    "        self.assertFalse(_flatten([[[1]], [[2]]]) == [[1], 2]) # Output should be [[1], [2]]\n",
    "        self.assertTrue(_flatten([[1], [\"a\"], [2], [\"b\"]]), [1, \"a\", 2, \"b\"])\n",
    "        self.assertTrue(_flatten([[]]) == [])\n",
    "        \n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.033s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a40153208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def test_clean_text(self):\n",
    "        \"\"\"\n",
    "        Test function _clean_text\n",
    "        \"\"\"\n",
    "        # test for lowercase\n",
    "        self.assertEqual(_clean_text(\"ABC\"), \"abc\")\n",
    "        # test for stopword removal\n",
    "        self.assertEqual(_clean_text(\"the food is nice.\"), \"food nice .\")\n",
    "        # test for removing quotations that surround words\n",
    "        self.assertEqual(_clean_text(\"'food' 'is' 'nice'\"), \"food nice\")\n",
    "        # test for contraction he's, she's and it's (if not expanded, then \"'s\" will not be treated as a stopword)\n",
    "        self.assertEqual(_clean_text(\"He's a good boy and she's a good girl. It's not a good dog.\"), \\\n",
    "                                     \"good boy good girl . good dog .\")\n",
    "        # test for contraction can't, 'll, n't (if not expanded, then they might not be treated as a stopword)\n",
    "        self.assertEqual(_clean_text(\"I don't think I can't win the game but I'll lose him if you didn't ask me.\"), \\\n",
    "                                     \"think win game lose ask .\")\n",
    "        # test for contraction i'm and 're (if not expanded, then \"'s\" will not be treated as a stopword)\n",
    "        self.assertEqual(_clean_text(\"I'm not going to that place but you're going to that place.\"), \\\n",
    "                                     \"going place going place .\")\n",
    "        # test for multiple consecutive whitespace removal\n",
    "        self.assertEqual(_clean_text(\"dim     sum     is     good\"), \\\n",
    "                                     \"dim sum good\")\n",
    "        # test for starting and ending whitespace removal\n",
    "        self.assertEqual(_clean_text(\" dim sum is good \"), \\\n",
    "                                     \"dim sum good\")\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.032s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a46bb5c18>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.test_xml_file1 = \"./Datasets/test_readXML_1.xml\"\n",
    "        self.test_xml_file2 = \"./Datasets/test_readXML_2.xml\"\n",
    "\n",
    "    def test_readXML(self):\n",
    "        \"\"\"\n",
    "        test function _readXML\n",
    "        \"\"\"\n",
    "        # Dataframes created from our function\n",
    "        df1 = _readXML(self.test_xml_file1)\n",
    "        df2 = _readXML(self.test_xml_file2)\n",
    "\n",
    "        # Manually created dataframes\n",
    "        check_df1 = pd.DataFrame(columns=['review', 'term', 'termPolarity', 'startIndex', 'endIndex','aspect', 'aspectPolarity'])\n",
    "        check_df1 = check_df1.append(pd.Series(['The food is nice!', ['food'], \\\n",
    "                                    ['positive'], [4], [8], ['food'], ['positive']], \\\n",
    "                                   index=check_df1.columns ), ignore_index=True)\n",
    "        check_df1 = check_df1.append(pd.Series(['It would be better if there are some peppers on it.', ['peppers'], \\\n",
    "                                    ['neutral'], [37], [44], ['food'], ['neutral']], \\\n",
    "                                   index=check_df1.columns ), ignore_index=True)\n",
    "        \n",
    "        check_df2 = pd.DataFrame(columns=['review', 'term', 'termPolarity', 'startIndex', 'endIndex','aspect', 'aspectPolarity'])\n",
    "        check_df2 = check_df2.append(pd.Series(['I hate that waiter.', ['waiter'], \\\n",
    "                                    ['negative'], [12], [18], ['service'], ['negative']], \\\n",
    "                                   index=check_df2.columns ), ignore_index=True)\n",
    "        check_df2 = check_df2.append(pd.Series(['The fish and chips is so delicious.', ['fish and chips'], \\\n",
    "                                    ['positive'], [4], [18], ['food'], ['positive']], \\\n",
    "                                   index=check_df2.columns ), ignore_index=True)        \n",
    "\n",
    "        # Check whether they are equal\n",
    "        self.assertTrue(df1.equals(check_df1))\n",
    "        self.assertTrue(df2.equals(check_df2))        \n",
    "        \n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.017s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a4900f978>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.sentences1 = [\n",
    "            \"The food is nice!\",\n",
    "            \"It would be better if there are some peppers on it.\"\n",
    "        ]\n",
    "        self.sentences2 = [\n",
    "            \"I hate that waiter.\",\n",
    "            \"The fish and chips is so delicious.\"\n",
    "        ]\n",
    "\n",
    "    def test_add6PosFeatures(self):\n",
    "        \"\"\"\n",
    "        test function _add6PosFeatures\n",
    "        \"\"\" \n",
    "        # Part-of-Speech sequence = [\"CC\",\"IN\",\"JJ\",\"NN\",\"RB\",\"VB\"]\n",
    "        # Max Sentence Length = 65\n",
    "        # The Part-of-Speech features provided by our function\n",
    "        pos_features1 = _add6PosFeautures(self.sentences1)\n",
    "        pos_features2 = _add6PosFeautures(self.sentences2)\n",
    "        \n",
    "        # Manually created Part-of-Speech features\n",
    "        features1 = np.zeros((len(self.sentences1), 65, 6))\n",
    "        for i, sentence in enumerate(self.sentences1):\n",
    "            words1 = text_to_word_sequence(sentence)\n",
    "            pos1 = nltk.pos_tag(words1)\n",
    "            for j, pos in enumerate(pos1):\n",
    "                if pos[1][:2] == \"CC\":\n",
    "                    features1[i][j][0] = 1\n",
    "                elif pos[1][:2] == \"NN\":\n",
    "                    features1[i][j][3] = 1\n",
    "                elif pos[1][:2] == \"JJ\":\n",
    "                    features1[i][j][2] = 1\n",
    "                elif pos[1][:2] == \"VB\":\n",
    "                    features1[i][j][5] = 1\n",
    "                elif pos[1][:2] == \"RB\":\n",
    "                    features1[i][j][4] = 1\n",
    "                elif pos[1][:2] == \"IN\":\n",
    "                    features1[i][j][1] = 1\n",
    "                    \n",
    "        features2 = np.zeros((len(self.sentences2), 65, 6))\n",
    "        for i, sentence in enumerate(self.sentences2):\n",
    "            words2 = text_to_word_sequence(sentence)\n",
    "            pos2 = nltk.pos_tag(words2)\n",
    "            for j, pos in enumerate(pos2):\n",
    "                if pos[1][:2] == \"CC\":\n",
    "                    features2[i][j][0] = 1\n",
    "                elif pos[1][:2] == \"NN\":\n",
    "                    features2[i][j][3] = 1\n",
    "                elif pos[1][:2] == \"JJ\":\n",
    "                    features2[i][j][2] = 1\n",
    "                elif pos[1][:2] == \"VB\":\n",
    "                    features2[i][j][5] = 1\n",
    "                elif pos[1][:2] == \"RB\":\n",
    "                    features2[i][j][4] = 1\n",
    "                elif pos[1][:2] == \"IN\":\n",
    "                    features2[i][j][1] = 1\n",
    "        \n",
    "        # Check whether they are equal\n",
    "        self.assertTrue(np.array_equal(pos_features1, features1))\n",
    "        self.assertTrue(np.array_equal(pos_features2, features2))\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a42aa6a58>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.unique_asp = [\"service\",\"food\",\"price\",\"ambience\",\"anecdotes/miscellaneous\"]\n",
    "        self.mlb = MultiLabelBinarizer(classes=[i for i in range(5)])\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(self.unique_asp)\n",
    "\n",
    "    def test_oneHotVectorize(self):\n",
    "        \"\"\"\n",
    "        test function _oneHotVectorize\n",
    "        \"\"\"\n",
    "        df1 = pd.DataFrame([\n",
    "            [[\"service\"]],\n",
    "            [[\"service\",\"price\"]]\n",
    "          ], columns=[\"aspect\"])\n",
    "        \n",
    "        df2 = pd.DataFrame([\n",
    "            [[\"food\"]],\n",
    "            [[\"food\",\"service\",\"price\"]]\n",
    "          ], columns=[\"aspect\"])\n",
    "        \n",
    "        # encoded labels by our function\n",
    "        labels1 = _oneHotVectorize(df1[\"aspect\"], self.mlb, self.le)\n",
    "        labels2 = _oneHotVectorize(df2[\"aspect\"], self.mlb, self.le)        \n",
    "        \n",
    "        # manually encoded labels  \n",
    "        check_df1 = []\n",
    "        check_df2 = []\n",
    "        for i in range(2):\n",
    "            l = []\n",
    "            l2 = []\n",
    "            for j in range(5):\n",
    "                l.append(0)\n",
    "                l2.append(0)\n",
    "            check_df1.append(l)\n",
    "            check_df2.append(l2)\n",
    "            \n",
    "        for i,row in enumerate(df1[\"aspect\"]):\n",
    "            for j,aspect in enumerate(row):\n",
    "                if aspect == \"service\":\n",
    "                    check_df1[i][4]=1\n",
    "                elif aspect == \"food\":\n",
    "                    check_df1[i][2]=1\n",
    "                elif aspect == \"price\":\n",
    "                    check_df1[i][3]=1\n",
    "                elif aspect == \"ambience\":\n",
    "                    check_df1[i][0]=1\n",
    "                else:\n",
    "                    check_df1[i][1]=1\n",
    "                    \n",
    "        for i,row in enumerate(df2[\"aspect\"]):\n",
    "            for j,aspect in enumerate(row):\n",
    "                if aspect == \"service\":\n",
    "                    check_df2[i][4]=1\n",
    "                elif aspect == \"food\":\n",
    "                    check_df2[i][2]=1\n",
    "                elif aspect == \"price\":\n",
    "                    check_df2[i][3]=1\n",
    "                elif aspect == \"ambience\":\n",
    "                    check_df2[i][0]=1\n",
    "                else:\n",
    "                    check_df2[i][1]=1\n",
    "        check_df1 = np.asarray(check_df1)\n",
    "        check_df2 = np.asarray(check_df2)\n",
    "        \n",
    "        # check whether they are equal\n",
    "        self.assertTrue(np.array_equal(labels1, check_df1))\n",
    "        self.assertTrue(np.array_equal(labels2, check_df2))\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a49c840b8>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFunc(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This function is to create some examples used for testing\n",
    "        \"\"\"\n",
    "        self.predicted1 = [\n",
    "            [0.0,0.0,0.45,0.45,0.1],\n",
    "            [0.0,0.0,0.9,0.05,0.05],\n",
    "            [1.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.9,0.1]\n",
    "        ]\n",
    "\n",
    "        self.actual1 = [\n",
    "            [0,0,1,0,1],\n",
    "            [0,0,1,0,0],\n",
    "            [0,0,0,1,0],\n",
    "            [1,1,1,1,0]\n",
    "        ]\n",
    "        \n",
    "        self.predicted2 = [\n",
    "            [1.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,1.0,0.0]\n",
    "        ]\n",
    "\n",
    "        self.actual2 = [\n",
    "            [0,0,0,1,0],\n",
    "            [1,1,1,1,0]\n",
    "        ]\n",
    "\n",
    "    def test_modified_performance_measure(self):\n",
    "        # result from our function\n",
    "        result1 = _modified_performance_measure(self.predicted1, self.actual1)\n",
    "        result2 = _modified_performance_measure(self.predicted2, self.actual2)\n",
    "        \n",
    "        # real result\n",
    "        real_result1 =[0.65, 0.38, 0.6, 0.46]\n",
    "        real_result2 = [0.50, 0.20, 0.50, 0.29]\n",
    "        \n",
    "        # check whether they are equal\n",
    "        self.assertTrue(result1 == real_result1)\n",
    "        self.assertTrue(result2 == real_result2)\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
