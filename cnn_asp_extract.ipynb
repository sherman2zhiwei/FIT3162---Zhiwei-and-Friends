{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hokongzheng/Downloads/FIT3162---Zhiwei-and-Friends\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# change directory if necessary\n",
    "print(os.getcwd())\n",
    "os.chdir(r\"/Users/hokongzheng/Downloads/FIT3162---Zhiwei-and-Friends/\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    data = pd.read_excel(filename)\n",
    "    data = data.dropna(subset=[\"text\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SemEval dataset\n",
    "filename = \"Restaurants_Train.xlsx\"\n",
    "data = readfile(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspectTerms</th>\n",
       "      <th>aspectTerm</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>aspectCategories</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3121.0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>staff</td>\n",
       "      <td>negative</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td>57.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>583.0</td>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentences  sentence      id  \\\n",
       "0        NaN       NaN  3121.0   \n",
       "1        NaN       NaN  2777.0   \n",
       "3        NaN       NaN  1634.0   \n",
       "6        NaN       NaN  2534.0   \n",
       "7        NaN       NaN   583.0   \n",
       "\n",
       "                                                text  aspectTerms  aspectTerm  \\\n",
       "0               But the staff was so horrible to us.          NaN         NaN   \n",
       "1  To be completely fair, the only redeeming fact...          NaN         NaN   \n",
       "3  The food is uniformly exceptional, with a very...          NaN         NaN   \n",
       "6  Where Gabriela personaly greets you and recomm...          NaN         NaN   \n",
       "7  For those that go once and don't enjoy it, all...          NaN         NaN   \n",
       "\n",
       "    term  polarity  from    to  aspectCategories  aspectCategory  \\\n",
       "0  staff  negative   8.0  13.0               NaN             NaN   \n",
       "1   food  positive  57.0  61.0               NaN             NaN   \n",
       "3   food  positive   4.0   8.0               NaN             NaN   \n",
       "6    NaN       NaN   NaN   NaN               NaN             NaN   \n",
       "7    NaN       NaN   NaN   NaN               NaN             NaN   \n",
       "\n",
       "                  category polarity.1  \n",
       "0                  service   negative  \n",
       "1                     food   positive  \n",
       "3                     food   positive  \n",
       "6                  service   positive  \n",
       "7  anecdotes/miscellaneous   positive  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspectTerms</th>\n",
       "      <th>aspectTerm</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>aspectCategories</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>But that is highly forgivable.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>777.0</td>\n",
       "      <td>From the appetizers we ate, the dim sum and ot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>appetizers</td>\n",
       "      <td>positive</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875.0</td>\n",
       "      <td>When we arrived at 6:00 PM, the restaurant was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>671.0</td>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>table</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>617.0</td>\n",
       "      <td>I am going to the mid town location next.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentences  sentence      id  \\\n",
       "4900        NaN       NaN  1063.0   \n",
       "4901        NaN       NaN   777.0   \n",
       "4905        NaN       NaN   875.0   \n",
       "4906        NaN       NaN   671.0   \n",
       "4912        NaN       NaN   617.0   \n",
       "\n",
       "                                                   text  aspectTerms  \\\n",
       "4900                     But that is highly forgivable.          NaN   \n",
       "4901  From the appetizers we ate, the dim sum and ot...          NaN   \n",
       "4905  When we arrived at 6:00 PM, the restaurant was...          NaN   \n",
       "4906  Each table has a pot of boiling water sunken i...          NaN   \n",
       "4912          I am going to the mid town location next.          NaN   \n",
       "\n",
       "      aspectTerm        term  polarity  from    to  aspectCategories  \\\n",
       "4900         NaN         NaN       NaN   NaN   NaN               NaN   \n",
       "4901         NaN  appetizers  positive   9.0  19.0               NaN   \n",
       "4905         NaN         NaN       NaN   NaN   NaN               NaN   \n",
       "4906         NaN       table   neutral   5.0  10.0               NaN   \n",
       "4912         NaN         NaN       NaN   NaN   NaN               NaN   \n",
       "\n",
       "      aspectCategory                 category polarity.1  \n",
       "4900             NaN  anecdotes/miscellaneous   positive  \n",
       "4901             NaN                     food   positive  \n",
       "4905             NaN  anecdotes/miscellaneous    neutral  \n",
       "4906             NaN                     food    neutral  \n",
       "4912             NaN  anecdotes/miscellaneous    neutral  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aspectTerms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aspectTerm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>polarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aspectCategories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aspectCategory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polarity.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Keys\n",
       "1          sentences\n",
       "2           sentence\n",
       "3                 id\n",
       "4               text\n",
       "5        aspectTerms\n",
       "6         aspectTerm\n",
       "7               term\n",
       "8           polarity\n",
       "9               from\n",
       "10                to\n",
       "11  aspectCategories\n",
       "12    aspectCategory\n",
       "13          category\n",
       "14        polarity.1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = pd.DataFrame(data.keys())\n",
    "keys.index += 1\n",
    "keys = keys.rename(columns={0:\"Keys\"})\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews: 3044\n"
     ]
    }
   ],
   "source": [
    "reviews = data[\"text\"]\n",
    "print(\"Number of Reviews:\", len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit Aspects: service, food, anecdotes/miscellaneous, ambience, price\n"
     ]
    }
   ],
   "source": [
    "ex_asp = pd.unique(data[\"category\"])\n",
    "print(\"Explicit Aspects:\", \", \".join(ex_asp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ex.Asp</th>\n",
       "      <th>Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambience</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>service</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Ex.Asp   Num\n",
       "1                 ambience   261\n",
       "2  anecdotes/miscellaneous  1082\n",
       "3                     food  1158\n",
       "4                    price   133\n",
       "5                  service   410"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_asp_freq_table = data.groupby(\"category\").size().reset_index()\n",
    "ex_asp_freq_table = ex_asp_freq_table.rename(columns={\"category\":\"Ex.Asp\", 0:\"Num\"})\n",
    "ex_asp_freq_table.index +=1\n",
    "ex_asp_freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c528f6eb9be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masp_polarity_freq_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"polarity.1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0masp_polarity_freq_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masp_polarity_freq_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Ex.Asp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"polarity.1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Polarity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Num\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0masp_polarity_freq_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0masp_polarity_freq_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "asp_polarity_freq_table = data.groupby([\"category\", \"polarity.1\"]).size().reset_index()\n",
    "asp_polarity_freq_table = asp_polarity_freq_table.rename(columns={\"category\":\"Ex.Asp\", \"polarity.1\":\"Polarity\", 0:\"Num\"})\n",
    "asp_polarity_freq_table.index +=1\n",
    "asp_polarity_freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------\n",
    "# Testing 123\n",
    "# -----------\n",
    "#### Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Reshape, Flatten, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training, testing, validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['text']\n",
    "labels = data['term']\n",
    "### rmb to remove conflict\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews, labels, test_size = 0.4, random_state=999)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size = 0.5, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     staff\n",
       "1                                      food\n",
       "3                                      food\n",
       "6                                       NaN\n",
       "7                                       NaN\n",
       "8                                      food\n",
       "10                                      NaN\n",
       "12      orrechiete with sausage and chicken\n",
       "16                                   Bagels\n",
       "17                                     food\n",
       "18                                    songs\n",
       "19                                    toast\n",
       "26                                   drinks\n",
       "28                                   design\n",
       "30                                  cuisine\n",
       "31                                      NaN\n",
       "32                                    pizza\n",
       "34                                      NaN\n",
       "35                                      NaN\n",
       "36                                      NaN\n",
       "37                                      NaN\n",
       "38                                      NaN\n",
       "39                                      NaN\n",
       "40                                      NaN\n",
       "42                                      NaN\n",
       "43                                      NaN\n",
       "44                      interior decoration\n",
       "46                                    seats\n",
       "47                        seltzer with lime\n",
       "48                                      NaN\n",
       "                       ...                 \n",
       "4869                                    NaN\n",
       "4870                                hostess\n",
       "4873                                    NaN\n",
       "4874                                  pizza\n",
       "4875                                    NaN\n",
       "4876                         dinosaur rolls\n",
       "4878                                    NaN\n",
       "4879                                    NaN\n",
       "4880                                    NaN\n",
       "4881                                    NaN\n",
       "4882                                    NaN\n",
       "4883                                Gnocchi\n",
       "4884                                    NaN\n",
       "4885                            reservation\n",
       "4886                                    NaN\n",
       "4887                                    NaN\n",
       "4888                                   beer\n",
       "4889                                    bar\n",
       "4890                                    NaN\n",
       "4891                                    NaN\n",
       "4892                                    NaN\n",
       "4893                                    NaN\n",
       "4894                                service\n",
       "4895                         bottle of sake\n",
       "4899                          cheese sticks\n",
       "4900                                    NaN\n",
       "4901                             appetizers\n",
       "4905                                    NaN\n",
       "4906                                  table\n",
       "4912                                    NaN\n",
       "Name: term, Length: 3044, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize text of the training data with keras preprocessing text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3471 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Set maximum number of words to be embedded\n",
    "NUM_WORDS = 100000\n",
    "\n",
    "# Set maximum length of a sentence\n",
    "MAX_LEN = 65\n",
    "\n",
    "# Define/Load Tokenize text function\n",
    "tokenizer = Tokenizer(num_words=NUM_WORD)\n",
    "\n",
    "# Fit the function on the text\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Count number of unique tokens\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and val to sequence\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_valid= tokenizer.texts_to_sequences(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train and X validation tensor: (1826, 65) (609, 65)\n",
      "Shape of label train and validation tensor: (1, 1826) (1, 609)\n"
     ]
    }
   ],
   "source": [
    "# Limit size of train/val to 50 and pad the sequence\n",
    "x_train = pad_sequences(sequences_train,maxlen=MAX_LEN)\n",
    "x_val = pad_sequences(sequences_valid,maxlen=x_train.shape[1])\n",
    "\n",
    "# Convert target to array\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "# Printing shape\n",
    "print('Shape of X train and X validation tensor:', x_train.shape,x_val.shape)\n",
    "print('Shape of label train and validation tensor:', y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "#### Using pretrained Word2Vec model from Google or Amazon\n",
    "#### Create 300-dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors = KeyedVectors.load_word2vec_format('./AmazonWE/sentic2vec.csv')\n",
    "word_vectors = pd.read_csv('./AmazonWE/sentic2vec.csv', encoding = \"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nycsamsung</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>-0.010965</td>\n",
       "      <td>0.034439</td>\n",
       "      <td>-0.003403</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>-0.016725</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.014179</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005171</td>\n",
       "      <td>0.027319</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>-0.017336</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>0.012654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>localizer</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>-0.051594</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>-0.010394</td>\n",
       "      <td>-0.010728</td>\n",
       "      <td>0.096014</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087075</td>\n",
       "      <td>-0.005560</td>\n",
       "      <td>-0.016801</td>\n",
       "      <td>0.044161</td>\n",
       "      <td>-0.010343</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>-0.026794</td>\n",
       "      <td>-0.046406</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.046562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gah</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>-0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasselfree</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>-0.035235</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.034341</td>\n",
       "      <td>-0.010994</td>\n",
       "      <td>-0.012281</td>\n",
       "      <td>0.020808</td>\n",
       "      <td>-0.034909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010619</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>-0.021808</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>-0.023384</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>0.028458</td>\n",
       "      <td>-0.030321</td>\n",
       "      <td>-0.042621</td>\n",
       "      <td>-0.011562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prendeel</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>-0.035391</td>\n",
       "      <td>-0.012458</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>-0.019798</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>-0.012590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015791</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>-0.038128</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>-0.023151</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>-0.017844</td>\n",
       "      <td>0.033579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0  nycsamsung  0.017007 -0.010965  0.034439 -0.003403  0.001669 -0.016725   \n",
       "1   localizer  0.038885  0.059859 -0.051594  0.021452  0.001800 -0.010394   \n",
       "2         gah  0.000715 -0.001516 -0.000800 -0.000104 -0.000850 -0.000913   \n",
       "3  hasselfree  0.014361 -0.000866 -0.035235  0.024500  0.034341 -0.010994   \n",
       "4    prendeel  0.025254  0.015678 -0.035391 -0.012458  0.045409 -0.019798   \n",
       "\n",
       "        7         8         9      ...          291       292       293  \\\n",
       "0 -0.009386 -0.014179  0.006383    ...    -0.005171  0.027319 -0.007168   \n",
       "1 -0.010728  0.096014  0.012083    ...    -0.087075 -0.005560 -0.016801   \n",
       "2  0.000452 -0.001184 -0.000177    ...    -0.000289  0.000471  0.001467   \n",
       "3 -0.012281  0.020808 -0.034909    ...    -0.010619  0.013001 -0.021808   \n",
       "4 -0.004205  0.014728 -0.012590    ...    -0.015791  0.002601 -0.038128   \n",
       "\n",
       "        294       295       296       297       298       299       300  \n",
       "0  0.010212 -0.017336  0.003275 -0.001003  0.011749 -0.004390  0.012654  \n",
       "1  0.044161 -0.010343  0.055683 -0.026794 -0.046406 -0.002826  0.046562  \n",
       "2 -0.000577  0.000112 -0.000166  0.001002  0.000662 -0.000665 -0.001045  \n",
       "3  0.006658 -0.023384  0.019640  0.028458 -0.030321 -0.042621 -0.011562  \n",
       "4  0.007929  0.001784  0.023809 -0.023151 -0.005321 -0.017844  0.033579  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=300\n",
    "vocabulary_size=min(len(word_index)+1,(NUM_WORDS))\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < vocabulary_size:\n",
    "        embedding_vector = word_vectors.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "#         else:\n",
    "#             vec = np.zeros(EMBEDDING_DIM)\n",
    "#             embedding_matrix[i] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding function using the embedding_matrix\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True,\n",
    "                            input_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build CNN with EarlyStopping\n",
    "What is unknown so far?\n",
    "- the structure of fully-connected layer\n",
    "- batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x_train.shape[1]\n",
    "filter_sizes = [2,3]\n",
    "num_filters = [100, 50]\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(embedding_layer)\n",
    "model.add(Reshape((sequence_length,EMBEDDING_DIM,1)))\n",
    "model.add(Conv2D(num_filters[0],(filter_sizes[0], filter_sizes[0]), activation='tanh'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(num_filters[1],(filter_sizes[1], filter_sizes[1]), activation='tanh'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(MAX_LEN, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 65, 300)           1041600   \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 65, 300, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 64, 299, 100)      500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 32, 149, 100)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 30, 147, 50)       45050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 15, 73, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 54750)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               5475100   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 65)                6565      \n",
      "=================================================================\n",
      "Total params: 6,578,915\n",
      "Trainable params: 6,578,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_24 to have shape (65,) but got array with shape (1826,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-b7329f2eb999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_24 to have shape (65,) but got array with shape (1826,)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=60,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
